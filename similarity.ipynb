{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n",
      "44\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/rishubtamirisa/NASA/bio-strategy-extractor/similarity.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rishubtamirisa/NASA/bio-strategy-extractor/similarity.ipynb#ch0000009?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoTokenizer,  AutoModelForTokenClassification, DataCollatorForTokenClassification, TrainingArguments, Trainer, AdamW, get_scheduler\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rishubtamirisa/NASA/bio-strategy-extractor/similarity.ipynb#ch0000009?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/rishubtamirisa/NASA/bio-strategy-extractor/similarity.ipynb#ch0000009?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpreprocess\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpre\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rishubtamirisa/NASA/bio-strategy-extractor/similarity.ipynb#ch0000009?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rishubtamirisa/NASA/bio-strategy-extractor/similarity.ipynb#ch0000009?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m DataLoader\n",
      "File \u001b[0;32m~/NASA/bio-strategy-extractor/preprocess.py:97\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     94\u001b[0m train_data \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(\u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mdata/dev_set.json\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m     95\u001b[0m test_data \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(\u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mdata/test_set.json\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m---> 97\u001b[0m test \u001b[39m=\u001b[39m FOBIE_preprocess(checkpoint, tokenizer, train_data)\n\u001b[1;32m     98\u001b[0m tokenized_dataset \u001b[39m=\u001b[39m create_train_test_dict(\n\u001b[1;32m     99\u001b[0m     FOBIE_preprocess(checkpoint, tokenizer, train_data), \n\u001b[1;32m    100\u001b[0m     FOBIE_preprocess(checkpoint, tokenizer, test_data)\n\u001b[1;32m    101\u001b[0m )\n",
      "File \u001b[0;32m~/NASA/bio-strategy-extractor/preprocess.py:68\u001b[0m, in \u001b[0;36mFOBIE_preprocess\u001b[0;34m(checkpoint, tokenizer, data)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(label))\n\u001b[1;32m     67\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(tokens))\n\u001b[0;32m---> 68\u001b[0m         \u001b[39mdict\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mlabels\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mappend(label)\n\u001b[1;32m     69\u001b[0m         \u001b[39mdict\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mtokens\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(tokens)\n\u001b[1;32m     70\u001b[0m \u001b[39m# dict['Train']['labels'] = np.array(dict['Train']['labels'])\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m# print(dict)\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'labels'"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer,  AutoModelForTokenClassification, DataCollatorForTokenClassification, TrainingArguments, Trainer, AdamW, get_scheduler\n",
    "import json\n",
    "import preprocess as pre\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "# import torch.optim.adamw as AdamW\n",
    "\n",
    "checkpoint = \"allenai/scibert_scivocab_cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "train_data = json.load(open(\"data/dev_set.json\"))\n",
    "test_data = json.load(open(\"data/test_set.json\"))\n",
    "tokenized_dataset = pre.create_train_test_dict(\n",
    "    pre.FOBIE_preprocess(checkpoint, tokenizer, train_data), \n",
    "    pre.FOBIE_preprocess(checkpoint, tokenizer, test_data)\n",
    ")\n",
    "\n",
    "tokenized_dataset\n",
    "# data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "\n",
    "# batch = data_collator([tokenized_dataset[\"train\"][i] for i in range(2)])\n",
    "# batch[\"labels\"]\n",
    "# data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "\n",
    "# train_dataloader = DataLoader(tokenized_dataset[\"train\"], batch_size=8, shuffle=True, collate_fn=data_collator)\n",
    "# test_dataloader = DataLoader(tokenized_dataset[\"test\"], batch_size=8, shuffle=True, collate_fn=data_collator)\n",
    "# model = AutoModelForTokenClassification.from_pretrained(checkpoint, num_labels=2)\n",
    "\n",
    "# # tokenized_dataset['train']['labels']\n",
    "# # batch = data_collator([tokenized_dataset[\"train\"][i] for i in range(3)])\n",
    "# # batch[\"labels\"]\n",
    "\n",
    "\n",
    "# # device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# device = torch.device('mps') # M1 Chip Device\n",
    "# model.to(device)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "92d548779f81c1a0d4f581d5b9bd270e2c1b74f140d6213b87e1406cdc999b34"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('nasa-petal')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
